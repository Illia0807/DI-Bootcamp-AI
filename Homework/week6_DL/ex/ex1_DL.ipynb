{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# EX1"
      ],
      "metadata": {
        "id": "Rd5F_rvO8kFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key difference between traditional ML and Deep Learning?**\n",
        "Traditional ML needs manual feature extraction. Deep Learning learns features automatically using multilayer neural networks.\n",
        "\n",
        "**How do neural networks imitate the human brain?**\n",
        "Neural networks have nodes (neurons) connected like brain neurons. They process signals and learn by adjusting connections.\n",
        "\n",
        "**Why is Deep Learning better with large datasets?**\n",
        "Big data helps deep networks find complex patterns and improve model accuracy.\n",
        "\n",
        "**Main problems of Deep Learning and how to fix them?**\n",
        "Problems: overfitting, need for lots of data, heavy computing. Fixes: regularization, Dropout, data augmentation, strong hardware.\n",
        "\n",
        "**What is feature engineering and why isn‚Äôt it needed in Deep Learning?**\n",
        "Feature engineering is manually creating features from raw data. Deep Learning does this automatically through layers.\n",
        "\n",
        "**Role of hidden layers?**\n",
        "Hidden layers transform input to find complex patterns that help predictions.\n",
        "\n",
        "**What does activation function do in an ANN?**\n",
        "It adds non-linearity so the network can learn complex functions, not just simple sums."
      ],
      "metadata": {
        "id": "9IstB76N8x2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2"
      ],
      "metadata": {
        "id": "-z2jjUnx89xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weighted Sum = (Temperature √ó 0.6) + (Rain √ó 0.4) + Bias\n",
        "Bias = 2\n",
        "**box 1:**\n",
        " Temp = 70, Rain = 0\n",
        "Weighted Sum = 70*0.6 + 0*0.4 + 2 = 42 + 0 + 2 = 44\n",
        "\n",
        "44 > 20 ‚Üí Exit = 1 (go outside)\n",
        "\n",
        "**box2:**\n",
        "Temp = 50, Rain = 1\n",
        "Weighted Sum = 50*0.6 + 1*0.4 + 2 = 30 + 0.4 + 2 = 32.4\n",
        "32.4 > 20 ‚Üí Exit = 1 (go outside)\n",
        "**summ**\n",
        "The perceptron suggests going outside in both cases because the weighted sum is above the threshold of 20. Even with rain and lower temperatures, the sum remains above the threshold due to the temperature weight and bias.\n"
      ],
      "metadata": {
        "id": "a74PmMX_8_JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise **3**"
      ],
      "metadata": {
        "id": "q9b-qD0r-UFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 3. One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 4. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. –ö–æ–º–ø–∏–ª—è—Ü–∏—è\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. –û–±—É—á–µ–Ω–∏–µ\n",
        "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# 7. –û—Ü–µ–Ω–∫–∞\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs7QUiXP-VtI",
        "outputId": "81080096-23db-4c5f-a93d-4c563a6c98b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8732 - loss: 0.4564 - val_accuracy: 0.9663 - val_loss: 0.1259\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1328 - val_accuracy: 0.9722 - val_loss: 0.0992\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.0866 - val_accuracy: 0.9757 - val_loss: 0.0839\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.0600 - val_accuracy: 0.9763 - val_loss: 0.0841\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0464 - val_accuracy: 0.9797 - val_loss: 0.0793\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0976\n",
            "Test accuracy: 0.9740999937057495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4N7EsSH9HPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4"
      ],
      "metadata": {
        "id": "ikgu_sD9xc4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = 2000  # –ø–ª–æ—â–∞–¥—å –≤ –∫–≤. —Ñ—É—Ç.\n",
        "x2 = 3     # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω\n",
        "\n",
        "w1 = 0.5   # –≤–µ—Å –¥–ª—è –ø–ª–æ—â–∞–¥–∏\n",
        "w2 = 0.7   # –≤–µ—Å –¥–ª—è —Å–ø–∞–ª–µ–Ω\n",
        "\n",
        "b = 50000  # —Å–º–µ—â–µ–Ω–∏–µ (bias)\n",
        "\n",
        "# üëâ –í—ã—á–∏—Å–ª—è–µ–º –ª–∏–Ω–µ–π–Ω—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏—é\n",
        "z = x1 * w1 + x2 * w2 + b\n",
        "\n",
        "print(f'z = {z}')\n",
        "\n",
        "# üëâ –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ReLU\n",
        "def relu(x):\n",
        "    return max(0, x)\n",
        "\n",
        "# üëâ –ü—Ä–∏–º–µ–Ω—è–µ–º ReLU\n",
        "output = relu(z)\n",
        "\n",
        "print(f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –¥–æ–º–∞: ${output:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE6saSw2xd59",
        "outputId": "49998ba9-53dd-4173-8206-032fdef5f983"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z = 51002.1\n",
            "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞ –¥–æ–º–∞: $51002.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5"
      ],
      "metadata": {
        "id": "u5zyDELUxvol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# –î–∞–Ω–Ω—ã–µ\n",
        "x = np.array([4, 80])  # 4 —á–∞—Å–∞ –∏ –æ—Ü–µ–Ω–∫–∞ 80\n",
        "w = np.array([0.6, 0.3])  # –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞\n",
        "b = 10  # –ù–∞—á–∞–ª—å–Ω—ã–π bias\n",
        "\n",
        "def forward_propagation(x, w, b):\n",
        "    z = np.dot(x, w) + b\n",
        "    return z\n",
        "\n",
        "y_pred = forward_propagation(x, w, b)\n",
        "y_true = 85\n",
        "\n",
        "loss = 0.5 * (y_true - y_pred) ** 2\n",
        "\n",
        "grad_w = -(y_true - y_pred) * x\n",
        "grad_b = -(y_true - y_pred)\n",
        "\n",
        "learning_rate = 0.01\n",
        "w_new = w - learning_rate * grad_w\n",
        "b_new = b - learning_rate * grad_b\n",
        "\n",
        "print(\"Initial Prediction:\", y_pred)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Updated Weights:\", w_new)\n",
        "print(\"Updated Bias:\", b_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVP_IFacyRs-",
        "outputId": "07176f10-8124-4782-ac09-6b4481e23505"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Prediction: 36.4\n",
            "Loss: 1180.98\n",
            "Updated Weights: [ 2.544 39.18 ]\n",
            "Updated Bias: 10.486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# –î–∞–Ω–Ω—ã–µ\n",
        "x = np.array([4, 80])  # 4 —á–∞—Å–∞ –∏ –æ—Ü–µ–Ω–∫–∞ 80\n",
        "w = np.array([0.1, 10.0])  # –ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞\n",
        "b = 10  # –ù–∞—á–∞–ª—å–Ω—ã–π bias\n",
        "\n",
        "def forward_propagation(x, w, b):\n",
        "    z = np.dot(x, w) + b\n",
        "    return z\n",
        "\n",
        "y_pred = forward_propagation(x, w, b)\n",
        "y_true = 85\n",
        "\n",
        "loss = 0.5 * (y_true - y_pred) ** 2\n",
        "\n",
        "grad_w = -(y_true - y_pred) * x\n",
        "grad_b = -(y_true - y_pred)\n",
        "\n",
        "learning_rate = 0.05\n",
        "w_new = w - learning_rate * grad_w\n",
        "b_new = b - learning_rate * grad_b\n",
        "\n",
        "print(\"Initial Prediction:\", y_pred)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Updated Weights:\", w_new)\n",
        "print(\"Updated Bias:\", b_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hghMYjZ5yWrG",
        "outputId": "bd0b645e-50ab-4695-e0b7-4a343feb1cea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Prediction: 810.4\n",
            "Loss: 263102.57999999996\n",
            "Updated Weights: [ -144.98 -2891.6 ]\n",
            "Updated Bias: -26.270000000000003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6"
      ],
      "metadata": {
        "id": "B4e-R6oXzRdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 3. One-hot –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 4. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 5. –ö–æ–º–ø–∏–ª—è—Ü–∏—è\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. –û–±—É—á–µ–Ω–∏–µ\n",
        "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
        "\n",
        "# 7. –û—Ü–µ–Ω–∫–∞\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
        "def plot_images(images, labels, preds, n=5):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.title(f\"True: {np.argmax(labels[i])}\\nPred: {np.argmax(preds[i])}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_images(x_test, y_test, predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "SlRilHRczUl-",
        "outputId": "46497854-bad6-4f59-d9ed-cee0bee685f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.4578 - val_accuracy: 0.9648 - val_loss: 0.1244\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.1317 - val_accuracy: 0.9735 - val_loss: 0.0932\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0816 - val_accuracy: 0.9727 - val_loss: 0.0904\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0627 - val_accuracy: 0.9773 - val_loss: 0.0799\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0441 - val_accuracy: 0.9765 - val_loss: 0.0814\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.0903\n",
            "Test accuracy: 0.9779999852180481\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}