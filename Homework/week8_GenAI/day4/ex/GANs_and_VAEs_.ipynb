{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Comparative Analysis of Generative AI and Traditional AI\n",
        "\n",
        "**1. Medical Diagnostics** Traditional AI (Classification) Rationale: In medicine, reliability, measurable accuracy, and predictability are critical. Traditional models like CNNs produce specific and verifiable classification results (cancer/not cancer).\n",
        "Risks of Generative AI: Using synthetic data for training can lead to unpredictable errors, as the generated images may not reflect the complexity and \"noise\" of real medical images. This creates a gap between synthetic and real data.\n",
        "\n",
        "**2. Legal Document** Generation Hybrid approach (traditional AI core, generative AI assistant) Rationale: Legal documents require absolute accuracy, unambiguity, and strict compliance with the law. Traditional rule-based systems provide this accuracy.\n",
        "Risks of generative AI: Generative models are prone to \"hallucinations\", creating plausible but legally incorrect text. Unlike essays, where subjectivity is important, in jurisprudence, errors can have catastrophic consequences.\n",
        "\n",
        "**3. Scientific research** (literature review and hypotheses) Generative AI (as a tool for co-authorship) Rationale: Generative AI is great at processing and summarizing huge amounts of text, which speeds up literature reviews. It can also find non-obvious statistical patterns to generate new hypotheses. Risks: The model may \"hallucinate\" facts or conclusions that are not in the original sources. Mandatory human verification of all generated hypotheses and references is required.\n",
        "\n",
        "**4. Financial Market Forecasting** Traditional AI (Time Series Analysis) Rationale: Stock market data is highly structured, and the challenge is to accurately forecast based on historical patterns. Traditional models (ARIMA, LSTM) are designed for this.\n",
        "Risks of Generative AI: The \"creativity\" of the generative model is a drawback. It can invent non-existent dependencies, which will lead to incorrect and costly forecasts.\n",
        "\n",
        "**5. Decision Making for Autonomous Vehicles** Traditional AI (Recognition and Prediction) Rationale: In self-driving cars, safety and instant reliability are paramount. Traditional models (CNN) are great for object recognition and prediction.\n",
        "Risks of Generative AI: AI \"hallucinations\" are especially dangerous here, as they can lead to fatal errors, and a person will not have time to correct them. Generative AI can only be useful for data augmentation (creating rare scenarios for training traditional models).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZzshHbH6_jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Ethical and Security Risks of Generative AI"
      ],
      "metadata": {
        "id": "_ct1HO8s7qZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Manipulating politics with deepfakes**\n",
        "\n",
        " 1. Losing trust in information: Blurring the line between reality and fiction.\n",
        "2. Manipulating elections: Disinformation influences public opinion, threatening democracy.\n",
        "3. Polarizing society: Inciting hatred and division.\n",
        " Technological: Deepfake detection systems with automatic labeling of generated content.\n",
        "Regulatory: Legislation on mandatory labeling of AI content and liability for disinformation.\n",
        "\n",
        "**2. Fraud using synthetic identities**\n",
        "1. Mass fraud: Opening accounts, obtaining loans on a huge scale.\n",
        "2. Undermining trust in biometrics: Making reliable systems vulnerable.\n",
        "3. Threat to national security: Use for espionage and unauthorized access. Technological: Multi-factor and \"live\" biometric verification (e.g. blinking, random words).\n",
        "Regulatory: Standardization of biometric protection and mandatory audit for resistance to synthetic attacks.\n",
        "\n",
        "**3. Generative AI in Cyber Warfare**\n",
        "1. Geopolitical Destabilization: False reports provoke conflicts and tensions.\n",
        "2. Erosion of trust between allies: Inability to trust intelligence.\n",
        "3. Threat Misjudgment: Diverting resources to non-existent threats. Technological: Digital verification and traceability of data (e.g. blockchain).\n",
        "Regulatory/Procedural: International protocols for sharing intelligence with mandatory cross-checking.\n",
        "\n",
        "**4. AI-generated malware**\n",
        "1. Constant adaptation: AI quickly creates new versions, bypassing defenses.\n",
        "2. Mass, personalized attacks: Increasing the probability of successful attacks.\n",
        "3. Threat to critical infrastructure: Creation of complex self-modifying viruses. Technological: Behavioral analysis instead of signature-based to detect threats.\n",
        "Regulatory/Procedural: International cooperation and information sharing on new threats.\n",
        "\n",
        "**5. Copyright and IP Theft **\n",
        "1. Collapse of the creative economy: Undermining the livelihoods of artists and creators.\n",
        "2. Erosion of originality: Blurring the line between inspiration and plagiarism.\n",
        "3. Legal uncertainty: Unclear who is the author and copyright holder. Technological: Watermarks or latent digital fingerprints in generated content.\n",
        "Regulatory/Procedural: New copyright laws governing the use of content for AI training and licensing/royalty mechanisms.\n",
        "\n"
      ],
      "metadata": {
        "id": "tNq7ts7cAF32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "34L5DXv87s7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VBnnZmR1sEt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒŸ Exercise 3: Optimization and Fine-Tuning of Generative AI Models"
      ],
      "metadata": {
        "id": "F_qORDeDAtqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Engineering Question:** What is the main goal of prompt engineering? Why is simply \"asking\" a generative AI to do something often not enough to get the desired result? Goal: To guide a generative model to the desired result as accurately and efficiently as possible, minimizing unpredictability and \"hallucinations\".\n",
        "Weakness: The model \"knows\" too much and without specificity can interpret requests in many ways, generating statistically probable but undesirable content. It needs clear boundaries and details to guide \"creativity\".\n",
        "\n",
        "**Bias in Data Question:** Why doesn't \"more data\" always mean \"less bias\"? When might adding more data actually make a bias problem worse? Rationale: If the underlying data source is inherently biased, adding more data from the same source will only make the problem worse by amplifying the existing bias. The model will \"absorb\" and reproduce these biases more deeply. The issue is one of quality and balance, not just quantity.\n",
        "\n",
        "**Fine-tuning Question:** What is the difference between fine-tuning and training a model from scratch? Why is fine-tuning especially important for highly specialized domains like medicine? Difference: The main difference is resources and time. Training from scratch requires enormous computing power and time. Fine-tuning uses an already trained model and adapts it to a new task with significantly less effort. Importance for the domain: The model already has extensive \"knowledge\" of the language. Fine-tuning allows it to adapt this knowledge to the specific terminology, style, and structure of the subject domain (e.g. medicine), without \"forgetting\" the general understanding of the language. This ensures accuracy and relevance in critical domains.\n",
        "\n",
        "**Performance Evaluation Question:** Why is \"human evaluation\" considered the gold standard for generative model quality, but it cannot be the only metric? What are its drawbacks? Gold standard: Humans can evaluate meaning, context, naturalness, and aesthetics at a level that automated metrics cannot.\n",
        "Drawbacks: Subjectivity and bias (different perceptions among different people), inconsistency (one person may evaluate differently), expensive and non-scalable (cannot evaluate millions of examples), blind to details and hidden patterns, and lack of detail about the causes of low quality.\n",
        "\n",
        "**Creativity vs. Noise Question:** What is the fundamental difference between the \"creativity\" we want to control in AI and random noise or nonsense? Why is it important to find a balance between the two? Creativity: The ability of a model to generate novel, varied, yet meaningful and relevant output. It is controlled randomness that leads to valuable results.\n",
        "Noise (Nonsense): Random data or sequences that do not carry any meaning, logic, or relevance. It is chaotic, purposeless output.\n",
        "Balance: Necessary to ensure that the model can generate original content (creativity), but also remain within the bounds of logic and relevance (control), avoiding meaningless or unwanted results (noise)."
      ],
      "metadata": {
        "id": "Jy3BnaJGu4YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Evaluating the Trade-offs Between GANs and VAEs"
      ],
      "metadata": {
        "id": "0Izlj7NjvQuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Synthetic Medical Image Generation** VAEs (core), GANs (improvement) VAEs are better suited for generating supervised, diverse, and labeled medical images due to their interpretable latent space. This allows for the creation of specific pathology variations. Although GANs produce higher visual quality, their uninterpretable latent space and training instability make them less suitable for purposeful training data generation. For training other models, diversity and supervisedness are more important than absolute photorealism.\n",
        "\n",
        "**2. Creative Writing with AI** VAEs VAEs are more useful for creative writing because their interpretable latent space allows control over style, mood, theme, and storylines. This gives the writer the ability to \"guide\" the AI in the creative process, interpolating between ideas. GANs are difficult to train on text (discrete data) and do not provide the same level of control over meaning and coherence, focusing on the local \"realism\" of the text rather than the global structure.\n",
        "\n",
        "**3. Detecting anomalies in financial transactions** VAEs VAEs are significantly more effective at detecting anomalies. They are explicitly trained on a \"normal\" data distribution, and anomalies show up as high reconstruction error because the VAE cannot accurately reconstruct what was not \"normal\" during training. GANs focus on generating new data and are less adept at modeling and analyzing the existing distribution, which is critical for highlighting outliers.\n",
        "\n",
        "**4. Generate High-Quality Fashion Designs** Hybrid Approach: VAEs (Concept), GANs (Finalization) For fashion designs, a hybrid approach is optimal. VAEs are great for exploring latent space, interpolating between styles, and generating varied but controlled concepts. This allows designers to mix and match elements and explore ideas. Once a concept has been selected, GANs can be used to enhance the visual quality and photorealism of the selected designs to a presentation-ready level, thanks to their ability to generate highly detailed images.\n",
        "\n",
        "**5. Data Augmentation for Autonomous Vehicle **Training GANs (for realism), VAEs (for variation control) In this scenario, GANs are often preferred for final data generation due to their superior photorealism, which is critical for training perception in autonomous vehicles. VAEs can be useful in the early stages to model and interpolate specific complex conditions (e.g., varying degrees of fog). Synthetic data with subtle, non-obvious artifacts is especially dangerous, as they can create new, unpredictable scenarios that the model cannot adequately respond to, jeopardizing safety.\n"
      ],
      "metadata": {
        "id": "Nq_sgqx0gFbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: Advanced Latent Space Exploration in VAEs"
      ],
      "metadata": {
        "id": "Msm6taUMnpwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the VAE generate only images of a certain type or with given characteristics when other data were present in the training set, conditional generation methods are used. The main approach is Conditional VAE (CVAE). The idea of \"freezing layers\" is closer to fine-tuning to adapt to a new task, and here we are talking about control during generation."
      ],
      "metadata": {
        "id": "XSspbLz-n7f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How Conditional VAEs (CVAEs) work:**\n",
        "\n",
        "Control Information Embedding: In CVAEs, we add additional \"conditional\" information (class label, attribute, text description) to both the encoder and decoder inputs.\n",
        "\n",
        "For the encoder: This allows it to learn how to encode an image given its label. For example, the encoder will know that this is an image of a cat, not a dog.\n",
        "\n",
        "For the decoder: This allows it to learn how to generate an image given a latent vector and label.\n",
        "\n",
        "Learning Process: During training, the model not only learns to encode and decode images, but also learns to do so conditionally based on the provided labels.\n",
        "\n",
        "Generating Process: To generate an image of a certain type (e.g. \"cat with green eyes\"), we:\n",
        "\n",
        "Create a random latent vector z.\n",
        "\n",
        "We feed the decoder this latent vector z ALONG with the desired conditional information (e.g. a vector representing \"cat with green eyes\").\n",
        "\n",
        "The decoder then generates an image that matches both the random noise from the latent space and the given feature.\n",
        "\n",
        "Advantages of CVAE:\n",
        "\n",
        "Precise control over generation: Allows generating objects of a specific class (only cats), specific attributes (only with green eyes), or even based on text descriptions.\n",
        "\n",
        "Using imbalanced data: Even if there were few cats with green eyes in the training set, the model will learn to generate them if this information was provided as conditional input.\n",
        "\n",
        "Other methods (less direct for this task, but relevant):\n",
        "\n",
        "Attribute discriminator: An additional classifier/discriminator can be trained that evaluates the VAE-generated images for the desired attributes, and uses it to select the best results (post-filtering).\n",
        "\n",
        "Latent Space Editing: As we discussed earlier, one can first train a VAE, then find directions in the latent space corresponding to \"cats\", \"dogs\", \"green eyes\", etc., and then generate by manipulating these vectors. CVAE automates this process by integrating control into the architecture itself."
      ],
      "metadata": {
        "id": "UWSjYO6PoGbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unconditional Generation:**\n",
        "\n",
        "How it works: The model generates data based only on random input noise (in case of GAN) or a random vector from the latent space (in case of VAE). There are no additional instructions or conditions.\n",
        "\n",
        "Goal: Create diverse data that is similar to the overall training set, without control over specific attributes.\n",
        "\n",
        "Relevance example:\n",
        "\n",
        "Generating random faces: We just want a lot of different, but realistic faces.\n",
        "\n",
        "Generating background images: We just want beautiful landscapes, no specific requirements.\n",
        "\n",
        "Data augmentation: We need to increase the overall volume of training data.\n",
        "\n",
        "**Conditional Generation:**\n",
        "\n",
        "How it works: The model generates data based on random input noise (or latent vector) and additional control conditions (labels, attributes, text). These conditions \"guide\" the generation process.\n",
        "\n",
        "Goal: Create data that is not only realistic, but also matches the given characteristics.\n",
        "\n",
        "Example of relevance:\n",
        "\n",
        "Face Generation with Attributes: Generate \"woman with red hair and glasses.\"\n",
        "\n",
        "Text-to-Image Synthesis: Generate an image of \"spaceship flying over mountains at sunset.\"\n",
        "\n",
        "Speech Synthesis: Generate a voice speaking a specific text, with a given timbre or emotion.\n",
        "\n",
        "Machine Translation: Generate a translation into a specific language.\n",
        "\n",
        "Key difference:\n",
        "Conditional generation gives us control over what the model generates, allowing us to get more specific and targeted results, whereas unconditional generation simply creates diversity from the general distribution of the data."
      ],
      "metadata": {
        "id": "JHA6TUczoRes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting Latent Space Question:** How is manipulation in VAE's latent space fundamentally different from traditional image editing using a photo editor (e.g. Photoshop)? What unique capabilities does VAE provide? Difference: Photoshop is a direct pixel manipulation, requiring a lot of manual effort for variations. VAE allows semantic manipulation of high-level features (age, emotion), offering infinite scalable variability and smooth transitions. Unique capabilities of VAE: Semantic controllability, interpolation/morphing, generation of new data with specified properties, and exploration of data structure.\n",
        "\n",
        "**Control over the latent space Question:** What is the difference between \"unconditional generation\" and \"conditional generation\" in the context of VAE? Provide examples where each is most appropriate. Difference:\n",
        "Unconditional generation: The model generates data based only on random noise, without any specific instructions. The goal is diversity similar to the overall training set. (Example: random faces, background images).\n",
        "Conditional generation (CVAE): The model generates data based on noise AND additional control conditions (labels, attributes). The goal is to generate data that matches the given characteristics. (Example: \"woman with red hair\", generated from a text description).\n",
        "CVAE allows precise control over the generated content.\n",
        "\n",
        "**Spatial Distortions and Morphing Question:** If the VAE latent space is not \"smooth\" (i.e., close points in the latent space do not correspond to similar points in the real space), what problems does this create when attempting to perform morphing? Problems:\n",
        "1. Gaps and \"jumps\": Instead of smooth transitions, there will be abrupt, disconnected changes between images.\n",
        "2. \"Garbage\" generation: Intermediate points in a non-smooth space will decode into meaningless, distorted images or noise.\n",
        "3. Loss of interpretability: Feature manipulation will become unpredictable.\n",
        "4. Unexplorability: No new meaningful variations will be found.\n",
        "Smoothness and continuity are important because they ensure that movement in the latent space results in smooth, meaningful changes in the generated data, which is critical for morphing and controlled transformations.\n",
        "\n"
      ],
      "metadata": {
        "id": "cCJgUc1HpGMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Edgo1ccLAz2U"
      }
    }
  ]
}